# -*- coding: utf-8 -*-
"""Change_Final_.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l2Khb-m71zWXgzgwQFCXZOZnV3T-vpFo

# Import Libraries
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb

from imblearn.over_sampling import SMOTE

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, LSTM, SimpleRNN

data = pd.read_csv("Android_Permission.csv")
data

data.shape

data.columns

data.describe()

plt.rcParams["figure.figsize"] = (10,5)
plt.rcParams["xtick.labelsize"] = 7
plt.rcParams['figure.dpi'] = 300
plt.rcParams['savefig.dpi'] = 300

def replace_mean(x):
    if x.dtype!='object':
        return x.fillna(x.mean())
    return x

data1 = data.apply(lambda x: replace_mean(x),axis=1)
data1

import matplotlib.pyplot as plt
import seaborn as sns

# 1. Filter numeric columns only
numeric_data = data.select_dtypes(include=[float, int])

# 2. Calculate correlations
correlation = numeric_data.corr().abs().unstack().sort_values(ascending=False)

# 3. Get top 10 correlated features (excluding self-correlations)
top_corr = correlation[correlation < 1].drop_duplicates().head(10)

# 4. Plot the bar chart
top_corr.plot(kind='bar', color='skyblue', figsize=(10, 5))
plt.title("Top Feature Correlations")
plt.ylabel("Correlation Coefficient")
plt.xticks(rotation=45)
plt.show()

import matplotlib.pyplot as plt

dangerous_permissions = data['Dangerous permissions count']
safe_permissions = data['Safe permissions count']

plt.hist([dangerous_permissions, safe_permissions], label=['Dangerous', 'Safe'], bins=20, alpha=0.7)
plt.title('Distribution of Dangerous and Safe Permissions Count')
plt.xlabel('Permissions Count')
plt.ylabel('Frequency')
plt.legend(loc='upper right')
plt.show()

# 2. Replace Histogram of Permissions Count with Pie Chart
dangerous_count = data['Dangerous permissions count'].sum()
safe_count = data['Safe permissions count'].sum()

plt.figure(figsize=(6,6))
plt.pie([dangerous_count, safe_count], labels=['Dangerous', 'Safe'], autopct='%1.1f%%', colors=['red', 'green'])
plt.title("Distribution of Dangerous vs. Safe Permissions")
plt.show()

avg_permissions_by_rating = data.groupby('Rating')[['Dangerous permissions count', 'Safe permissions count']].mean()
avg_permissions_by_rating.plot(kind='bar', figsize=(10, 5), color=['red', 'green'])
plt.title("Average Dangerous & Safe Permissions by Rating")
plt.xlabel("App Rating")
plt.ylabel("Average Permissions Count")
plt.xticks(rotation=45)
plt.legend(title="Permission Type")
plt.show()

rating_distribution = data['Rating'].value_counts()
plt.figure(figsize=(6,6))
plt.pie(rating_distribution, labels=rating_distribution.index, autopct='%1.1f%%', colors=sns.color_palette('pastel'))
plt.title("App Rating Distribution")
plt.show()

# Analyze the relationship between the number of ratings and app ratings:

import seaborn as sns

sns.scatterplot(x=data['Number of ratings'], y=data['Rating'])
# plt.figure(figsize=(10, 6))
plt.title('Relationship between Number of Ratings and App Ratings')
plt.xlabel('Number of Ratings')
plt.ylabel('App Rating')
plt.show()

category_dangerous_mean = data1.groupby('Category')['Dangerous permissions count'].mean()
category_safe_mean = data1.groupby('Category')['Safe permissions count'].mean()

categories = data1['Category'].unique()
x = np.arange(len(categories))
width = 0.4

fig, ax = plt.subplots(figsize=(20, 10))
rects1 = ax.bar(x - width/2, category_dangerous_mean, width, label='Dangerous')
rects2 = ax.bar(x + width/2, category_safe_mean, width, label='Safe')

ax.set_title('Average Permissions Count per Category')
ax.set_xlabel('Category')
ax.set_ylabel('Average Permissions Count')
ax.set_xticks(x)
ax.set_xticklabels(categories, rotation=45)
ax.legend()

plt.show()

# Analyze the distribution of each feature

# Get the list of features
features = data1.columns.tolist()

# Remove non-numeric features
features.remove('App')
features.remove('Package')
features.remove('Category')
features.remove('Description')
features.remove('Related apps')

count = 0
# Plot the distribution of each feature
for feature in features:
    if count < 5:
        plt.figure(figsize=(10, 6))
        sns.histplot(data[feature], kde=True)
        plt.title('Distribution of ' + feature)
        plt.xlabel(feature)
        plt.ylabel('Frequency')
        plt.show()
        count = count+1

pd.set_option('display.max_columns', None)
for col in data.columns:
    if data[col].isna().sum() > 0:
        print(col,data[col].isna().sum())

for col in data.columns:
    if data[col].dtypes == 'object':
        print(col, len(data[col].unique()))

data.info()

data.describe()

numeric_data = data.select_dtypes(include=['number'])
corr_matrix = round(numeric_data.corr(), 2)
print(corr_matrix)

dropper = []
for col in data1.columns[10:]:
    if (data1[col].value_counts()[0] == 29999 or data1[col].value_counts()[1] < 1500):
        dropper.append(col)
print(len(dropper))

def preprocess_inputs(data1,lst):
    data1 = data1.copy()
    data1 = data1.drop_duplicates()
    data1 = data1.drop(['App','Package','Description','Related apps'],axis=1)
    for i in lst:
        data1 = data1.drop(i,axis=1)
    data1 = data1.dropna(axis=0)
    encoder = LabelEncoder()
    data1['Category'] = encoder.fit_transform(data1['Category'])

    y = data1['Class']
    X = data1.drop('Class',axis=1)
    X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.7, shuffle=True, random_state=43)

    scaler = StandardScaler()
    scaler.fit(X_train)

    X_train = pd.DataFrame(scaler.transform(X_train), index = X_train.index, columns = X_train.columns)
    X_test = pd.DataFrame(scaler.transform(X_test), index = X_test.index, columns = X_test.columns)

    return X_train, X_test, y_train, y_test

X_train, X_test, y_train, y_test = preprocess_inputs(data1,lst=dropper)
X_train

smote = SMOTE(random_state=23)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

from sklearn.svm import SVC

models = {
    "Logistic Regression": LogisticRegression(),
    "K-Nearest Neighbors": KNeighborsClassifier(),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(),
    "Support Vector Machine": SVC(),
    "XGBoost": xgb.XGBClassifier(),
}

from sklearn.metrics import classification_report

# Dictionary to store classification reports
classification_reports = {}

# Ensure that X_test has the same columns as X_train_smote
missing_cols = set(X_train_smote.columns) - set(X_test.columns)
if missing_cols:
    for col in missing_cols:
        X_test[col] = 0  # Add missing columns with default value 0 (or NaN if preferred)

# Ensure column order matches
X_test = X_test[X_train_smote.columns]

# Loop through models and train
for name, model in models.items():
    model = model.fit(X_train_smote, y_train_smote)
    print(name + " trained")

    # Predict on test data
    y_pred = model.predict(X_test)

    # Generate classification report and store it
    report = classification_report(y_test, y_pred)
    classification_reports[name] = report

# Print classification reports
for name, report in classification_reports.items():
    print(f"\nClassification Report for {name}:")
    print(report)

for name, model in models.items():
    print(name + ": {:.2f}%".format(model.score(X_test, y_test) * 100))

import tensorflow as tf

inputs = tf.keras.Input(shape=(X_train_smote.shape[1],))

x = tf.keras.layers.Dense(128, activation = 'relu')(inputs)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Dense(64, activation = 'relu')(x)
x = tf.keras.layers.Dropout(0.6)(x)
x = tf.keras.layers.Dense(32, activation = 'relu')(x)
x = tf.keras.layers.Dropout(0.2)(x)

outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)


model = tf.keras.Model(inputs = inputs, outputs = outputs)

model.compile(optimizer="adam",
             loss="binary_crossentropy",
             metrics=["binary_accuracy"])
model.summary()

epochs=10
history = model.fit(
  X_train_smote,
  y_train_smote,
  validation_split=0.2,
  epochs=epochs,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(
            monitor="val_loss",
            patience=3,
            restore_best_weights=True
            )
    ]
)

loss, accuracy = model.evaluate(X_test, y_test)
print(f'My test loss is {loss*100:.2f}% and test accuracy is {accuracy*100:.2f}%')

from prettytable import PrettyTable


table = PrettyTable()


table.field_names = ["Epoch", "binary_accuracy", "loss", "val_binary_accuracy", "val_loss"]


table.add_row([1, 0.6256, 0.6414, 0.6442, 0.6983])
table.add_row([2, 0.6893, 0.5361, 0.8191, 0.6553])
table.add_row([3, 0.7170, 0.4976, 0.8928, 0.5976])
table.add_row([4, 0.7264, 0.4907, 0.8625, 0.6207])
table.add_row([5, 0.7333, 0.4789, 0.8809, 0.6020])
table.add_row([6, 0.7409, 0.4712, 0.8984, 0.5793])
table.add_row([7, 0.7391, 0.4664, 0.8970, 0.5853])
table.add_row([8, 0.7440, 0.4640, 0.8526, 0.6304])
table.add_row([9, 0.7428, 0.4625, 0.9202, 0.5656])
table.add_row([10, 0.7504, 0.4628, 0.8770, 0.6005])


print(table)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt


xgb_model = xgb.XGBClassifier()
xgb_model.fit(X_train_smote, y_train_smote)


y_pred_xgb = xgb_model.predict(X_test)


cm = confusion_matrix(y_test, y_pred_xgb)


disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix for XGBoost Classifier")
plt.show()

import matplotlib.pyplot as plt


models = ["Logistic Regression", "K-Nearest Neighbors", "Decision Tree",
          "Random Forest", "Support Vector Machine", "XGBoost"]
accuracies = [70.59, 71.20, 74.72, 77.66, 70.64, 80.70]


plt.figure(figsize=(10, 6))
plt.barh(models, accuracies, color='skyblue')
plt.xlabel("Accuracy (%)")
plt.title("Comparison of Algorithm Accuracies")


for index, value in enumerate(accuracies):
    plt.text(value, index, f"{value}%", va='center')

plt.show()

from prettytable import PrettyTable


table = PrettyTable()


table.field_names = ["Model", "Accuracy"]


table.add_row(["Logistic Regression", "70.59%"])
table.add_row(["Linear SVM", "70.64%"])
table.add_row(["XGBClassifier", "80.70%"])
table.add_row(["Gradient Boosting", "80.22%"])
table.add_row(["Decision Tree", "74.72%"])
table.add_row(["Random Forest", "77.66%"])



print(table)

dataset = pd.read_csv("Android_Permission.csv")

import pandas as pd

# Load dataset from a CSV file (replace 'your_dataset.csv' with actual filename)
dataset = pd.read_csv('Android_Permission.csv')

# Drop unnecessary columns for the model
data = dataset.drop(columns=['App', 'Package', 'Category', 'Description', 'Related apps'])

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
import xgboost as xgb
from sklearn.metrics import accuracy_score

# Drop unnecessary columns for the model (textual columns like app name, package, description won't be useful)
data = dataset.drop(columns=['App', 'Package', 'Category', 'Description', 'Related apps'])

# Handle missing values by using SimpleImputer to fill NaN with most frequent values
imputer = SimpleImputer(strategy='most_frequent')
data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)

# Encode categorical columns if necessary (already numeric except 'Class')
label_encoders = {}
for column in data_imputed.select_dtypes(include='object').columns:
    le = LabelEncoder()
    data_imputed[column] = le.fit_transform(data_imputed[column].astype(str))
    label_encoders[column] = le

# Split into features (X) and target (y)
X = data_imputed.drop(columns=['Class'])
y = data_imputed['Class'].astype(int)

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train the XGBoost classifier
xgb_classifier = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')
xgb_classifier.fit(X_train, y_train)

# Predict on the test set
y_pred = xgb_classifier.predict(X_test)

# Calculate the accuracy of the model
accuracy = accuracy_score(y_test, y_pred)

accuracy

import numpy as np

# Ensure the number of features matches the model's expected input
num_features = X_train.shape[1]
new_input = np.zeros((1, num_features))

# Set feature values (update based on the actual dataset)
new_input[0, :14] = np.array([
    1.0, 1, 0.5, 3, 0.0, 1, 0, 0, 0, 1, 1, 0, 0, 0
])

# Predict with the trained XGBoost classifier
prediction = xgb_classifier.predict(new_input)

# Output result
if prediction[0] == 1:
    print("This app is classified as malware.")
else:
    print("This app is classified as safe (not malware).")

import numpy as np

# Ensure the number of features matches the model's expected input
num_features = X_train.shape[1]
new_input_safe = np.zeros((1, num_features))

# Extract a "safe" app sample from the dataset
safe_apps = dataset[dataset['Class'] == 0]
safe_app_sample = safe_apps.drop(columns=['App', 'Package', 'Category', 'Description', 'Related apps', 'Class']).iloc[0]

# Convert to NumPy array and reshape for prediction
new_input_safe[0, :] = np.array(safe_app_sample)

# Predict with the trained XGBoost classifier
prediction_safe = xgb_classifier.predict(new_input_safe)

# Output result
if prediction_safe[0] == 1:
    print("This app is classified as malware.")
else:
    print("This app is classified as safe (not malware).")